{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111b23bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996b1dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/zuppif/lexica-6k\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://zuppif/lexica-6k loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "from vector_store import VectorStore\n",
    "\n",
    "vs = VectorStore.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d01ed4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zuppif/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/home/zuppif/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/home/zuppif/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n",
      "/home/zuppif/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.model_utils import get_model, get_images_embeddings, get_texts_embeddings, device\n",
    "import torch\n",
    "model = get_model(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9664723e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"compute_columns3d\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_embeddings\n\u001b[0;32m----> 3\u001b[0m embeddings \u001b[39m=\u001b[39m get_embeddings(model, [\u001b[39m\"\u001b[39;49m\u001b[39mCat\u001b[39;49m\u001b[39m\"\u001b[39;49m], [\u001b[39m\"\u001b[39;49m\u001b[39m/home/zuppif/Documents/Work/ActiveLoop/search-all/docs/images/bear.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m], \u001b[39mNone\u001b[39;49;00m)\u001b[39m.\u001b[39mvalues()\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/models/model_utils.py:52\u001b[0m, in \u001b[0;36mget_embeddings\u001b[0;34m(model, texts, images, audio, dtype)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m audio \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     inputs[ModalityType\u001b[39m.\u001b[39mAUDIO] \u001b[39m=\u001b[39m load_and_transform_audio_data(audio, device, dtype)\n\u001b[0;32m---> 52\u001b[0m embeddings \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     53\u001b[0m \u001b[39mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/models/imagebind_model.py:465\u001b[0m, in \u001b[0;36mImageBindModel.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     modality_value \u001b[39m=\u001b[39m modality_value\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m    461\u001b[0m         B \u001b[39m*\u001b[39m S, \u001b[39m*\u001b[39mmodality_value\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m:]\n\u001b[1;32m    462\u001b[0m     )\n\u001b[1;32m    464\u001b[0m \u001b[39mif\u001b[39;00m modality_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 465\u001b[0m     modality_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodality_preprocessors[modality_key](\n\u001b[1;32m    466\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{modality_key: modality_value}\n\u001b[1;32m    467\u001b[0m     )\n\u001b[1;32m    468\u001b[0m     trunk_inputs \u001b[39m=\u001b[39m modality_value[\u001b[39m\"\u001b[39m\u001b[39mtrunk\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    469\u001b[0m     head_inputs \u001b[39m=\u001b[39m modality_value[\u001b[39m\"\u001b[39m\u001b[39mhead\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/models/multimodal_preprocessors.py:278\u001b[0m, in \u001b[0;36mRGBDTPreprocessor.forward\u001b[0;34m(self, vision, depth, patch_mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m()\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m vision \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 278\u001b[0m     vision_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenize_input_and_cls_pos(\n\u001b[1;32m    279\u001b[0m         vision, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrgbt_stem, patch_mask\n\u001b[1;32m    280\u001b[0m     )\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m depth \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     depth_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenize_input_and_cls_pos(\n\u001b[1;32m    284\u001b[0m         depth, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdepth_stem, patch_mask\n\u001b[1;32m    285\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/models/multimodal_preprocessors.py:257\u001b[0m, in \u001b[0;36mRGBDTPreprocessor.tokenize_input_and_cls_pos\u001b[0;34m(self, input, stem, mask)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize_input_and_cls_pos\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, stem, mask):\n\u001b[1;32m    256\u001b[0m     \u001b[39m# tokens is of shape B x L x D\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m     tokens \u001b[39m=\u001b[39m stem(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    258\u001b[0m     \u001b[39massert\u001b[39;00m tokens\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m\n\u001b[1;32m    259\u001b[0m     \u001b[39massert\u001b[39;00m tokens\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/models/multimodal_preprocessors.py:152\u001b[0m, in \u001b[0;36mPatchEmbedGeneric.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 152\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproj(x)\n\u001b[1;32m    153\u001b[0m     \u001b[39m# B C (T) H W -> B (T)HW C\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mflatten(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:613\u001b[0m, in \u001b[0;36mConv3d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 613\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:608\u001b[0m, in \u001b[0;36mConv3d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv3d(\n\u001b[1;32m    598\u001b[0m         F\u001b[39m.\u001b[39mpad(\n\u001b[1;32m    599\u001b[0m             \u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[0;32m--> 608\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv3d(\n\u001b[1;32m    609\u001b[0m     \u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups\n\u001b[1;32m    610\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"compute_columns3d\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "from models.model_utils import get_embeddings\n",
    "\n",
    "embeddings = get_embeddings(model, [\"Cat\"], [\"/home/zuppif/Documents/Work/ActiveLoop/search-all/docs/images/bear.jpg\"], None, dtype=torch.float32).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.stack(list(embeddings), dim=0).sum(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, query_res = vs.retrieve(embedding.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d7f943",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'<class 'deeplake.core.dataset.deeplake_cloud_dataset.DeepLakeCloudDataset'>' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTensorDoesNotExistError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/deeplake/core/dataset/dataset.py:1287\u001b[0m, in \u001b[0;36mDataset.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(key)\n\u001b[1;32m   1288\u001b[0m \u001b[39mexcept\u001b[39;00m TensorDoesNotExistError \u001b[39mas\u001b[39;00m ke:\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/deeplake/core/dataset/dataset.py:509\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, item, is_iteration)\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m         \u001b[39mraise\u001b[39;00m TensorDoesNotExistError(item)\n\u001b[1;32m    510\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(item, (\u001b[39mint\u001b[39m, \u001b[39mslice\u001b[39m, \u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m, Index, \u001b[39mtype\u001b[39m(\u001b[39mEllipsis\u001b[39m))):\n",
      "\u001b[0;31mTensorDoesNotExistError\u001b[0m: \"Tensor 'score' does not exist.\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query_res\u001b[39m.\u001b[39;49mscore\n",
      "File \u001b[0;32m~/Documents/Work/ActiveLoop/search-all/.venv/lib/python3.8/site-packages/deeplake/core/dataset/dataset.py:1289\u001b[0m, in \u001b[0;36mDataset.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1287\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(key)\n\u001b[1;32m   1288\u001b[0m \u001b[39mexcept\u001b[39;00m TensorDoesNotExistError \u001b[39mas\u001b[39;00m ke:\n\u001b[0;32m-> 1289\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1291\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mke\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '<class 'deeplake.core.dataset.deeplake_cloud_dataset.DeepLakeCloudDataset'>' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "query_res.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b5bc5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"description\":\"Query successful.\",\"tensors\":[\"metadata\",\"score\"],\"data\":[{\"metadata\":{\"path\":\"000000139872.jpg\"},\"score\":0.28681132197380066},{\"metadata\":{\"path\":\"000000107226.jpg\"},\"score\":0.2819269001483917},{\"metadata\":{\"path\":\"000000052891.jpg\"},\"score\":0.2763610780239105},{\"metadata\":{\"path\":\"000000331075.jpg\"},\"score\":0.27589353919029236},{\"metadata\":{\"path\":\"000000089880.jpg\"},\"score\":0.2750997841358185}]}'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://app.activeloop.ai/api/query/v1\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer eyJhbGciOiJIUzUxMiIsImlhdCI6MTY4MzgxMDkzMywiZXhwIjoxNzE1NDMzMjk5fQ.eyJpZCI6Inp1cHBpZiJ9.DC3KLB6rS2RNpjnyH8rgtXk_oEH3SpgveaG8xRTlv_uSLmVUbBjZrD2SOHXqHADDUOlmGLkzmNoQ1Ond6rNQDQ\"\n",
    "    }\n",
    "\n",
    "request = {\n",
    "    \"query\": query,\n",
    "    \"as_list\": True # Defaults to True.\n",
    "    }\n",
    "\n",
    "\n",
    "res = requests.post(url, json=request, headers=headers)\n",
    "res.text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82790dc3",
   "metadata": {},
   "source": [
    "## Lexica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9544cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zuppif/miniconda3/envs/imagebind/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset parquet (/home/zuppif/.cache/huggingface/datasets/xfh___parquet/xfh--lexica_6k-f533396e266f1545/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"xfh/lexica_6k\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd2678c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '83ad9630-3d49-4063-98f9-878cc23d70bb', 'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x768 at 0x7F179C31B220>, 'width': 512, 'height': 768, 'md5': 'b664f486600965ef5df89f309ad31a40', 'tag': 'lexica'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for row in dataset:\n",
    "    image = row[\"image\"]\n",
    "    name = row[\"text\"]\n",
    "    image.save(f\"{row[name]}.jpg\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "79fae755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lexica', 'lexica', 'lexica', 'lexica', 'lexica', 'lexica', 'lexica', 'lexica']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "for i in range(0, len(dataset), batch_size):\n",
    "    rows = dataset[i: i + batch_size]\n",
    "    print(rows['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ea0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
